import streamlit as st
import pandas as pd
import re

st.set_page_config(page_title="LxU å¹¿å‘ŠæŠ•æ”¾æ¯”ä¾‹åˆ†æ", layout="wide")

st.title("ğŸ“ˆ å¹¿å‘ŠæŠ•æ”¾æ¯”ä¾‹ä¸å…³é”®è¯åˆ†æ")
st.markdown("è®¡ç®—æ¯ä¸ªå…³é”®è¯åŠ**éæœç´¢åŒºåŸŸ**åœ¨æ‰€å±äº§å“ä¸­çš„æ”¯å‡ºæ¯”ä¾‹ï¼Œç›‘æ§ Coupang æµé‡åˆ†å¸ƒã€‚")

uploaded_files = st.file_uploader("æ‰¹é‡ä¸Šä¼ æŠ¥è¡¨", type=['csv', 'xlsx'], accept_multiple_files=True)

if uploaded_files:
    all_data = []
    for file in uploaded_files:
        try:
            df = pd.read_csv(file, encoding='cp949') if file.name.endswith('.csv') else pd.read_excel(file)
            all_data.append(df)
        except:
            df = pd.read_csv(file, encoding='utf-8-sig')
            all_data.append(df)

    if all_data:
        raw_df = pd.concat(all_data, ignore_index=True)

        # 1. æå–å±æ€§
        def extract_info(row):
            camp_name = str(row.iloc[5]) if len(row) > 5 else ""
            grp_name = str(row.iloc[6]) if len(row) > 6 else ""
            full_text = f"{camp_name} {grp_name}"
            p_code = re.search(r'C\d{3,5}', full_text, re.IGNORECASE)
            p_code = p_code.group(0).upper() if p_code else "æœªè¯†åˆ«"
            target_match = re.search(r'ã€(\d+)ã€‘', full_text)
            target_val = int(target_match.group(1)) if target_match else 0
            date_match = re.search(r'ã€(\d{1,2}\.\d{1,2})ã€‘', full_text)
            mod_date = date_match.group(1) if date_match else "æœªçŸ¥"
            return pd.Series([p_code, target_val, mod_date])

        raw_df[['äº§å“ç¼–å·', 'ç›®æ ‡æŒ‡æ ‡', 'ç­–ç•¥æ—¥æœŸ']] = raw_df.apply(extract_info, axis=1)

        # 2. åˆ—åæ˜ å°„ä¸å…³é”®è¯æ¸…æ´—
        analysis_df = raw_df.copy()
        analysis_df.iloc[:, 12] = analysis_df.iloc[:, 12].fillna("éæœç´¢åŒºåŸŸ")

        analysis_df = analysis_df.rename(columns={
            analysis_df.columns[11]: 'å±•ç¤ºç‰ˆé¢',
            analysis_df.columns[12]: 'å…³é”®è¯',
            analysis_df.columns[13]: 'æ€»å±•ç¤º',
            analysis_df.columns[14]: 'æ€»ç‚¹å‡»',
            analysis_df.columns[15]: 'åŸå§‹å¹¿å‘Šè´¹',
            analysis_df.columns[29]: 'æ€»é”€é‡(å•æ•°)',
            analysis_df.columns[32]: 'æ€»è½¬åŒ–é”€å”®é¢'
        })

        # 3. èšåˆè®¡ç®—
        keyword_summary = analysis_df.groupby(['äº§å“ç¼–å·', 'å±•ç¤ºç‰ˆé¢', 'å…³é”®è¯', 'ç›®æ ‡æŒ‡æ ‡', 'ç­–ç•¥æ—¥æœŸ']).agg({
            'æ€»å±•ç¤º': 'sum',
            'æ€»ç‚¹å‡»': 'sum',
            'åŸå§‹å¹¿å‘Šè´¹': 'sum',
            'æ€»é”€é‡(å•æ•°)': 'sum',
            'æ€»è½¬åŒ–é”€å”®é¢': 'sum'
        }).reset_index()

        # è®¡ç®—å«ç¨æ”¯å‡º
        keyword_summary['çœŸå®å¹¿å‘Šè´¹(å«ç¨)'] = (keyword_summary['åŸå§‹å¹¿å‘Šè´¹'] * 1.1).round(0)

        # --- æ ¸å¿ƒæ”¹è¿›ï¼šè®¡ç®—æ”¯å‡ºå æ¯” ---
        # 1. è®¡ç®—æ¯ä¸ªäº§å“çš„æ€»æ”¯å‡º
        product_total_spend = keyword_summary.groupby('äº§å“ç¼–å·')['çœŸå®å¹¿å‘Šè´¹(å«ç¨)'].transform('sum')
        # 2. è®¡ç®—å æ¯”
        keyword_summary['æ”¯å‡ºå æ¯”'] = (keyword_summary['çœŸå®å¹¿å‘Šè´¹(å«ç¨)'] / product_total_spend * 100).round(2)

        # 4. æŒ‡æ ‡äºŒæ¬¡è®¡ç®—
        keyword_summary['çœŸå®ROAS'] = (keyword_summary['æ€»è½¬åŒ–é”€å”®é¢'] / keyword_summary['çœŸå®å¹¿å‘Šè´¹(å«ç¨)'] * 100).round(2)
        keyword_summary['çœŸå®ç‚¹å‡»ç‡'] = (keyword_summary['æ€»ç‚¹å‡»'] / keyword_summary['æ€»å±•ç¤º'] * 100).round(2)
        keyword_summary['çœŸå®CPC'] = (keyword_summary['çœŸå®å¹¿å‘Šè´¹(å«ç¨)'] / keyword_summary['æ€»ç‚¹å‡»']).round(0)

        keyword_summary = keyword_summary.replace([float('inf'), -float('inf')], 0).fillna(0)

        # 5. ç›ˆäºçŠ¶æ€åˆ¤å®š
        def check_status(row):
            if row['ç›®æ ‡æŒ‡æ ‡'] == 0: return "æœªè®¾ç›®æ ‡"
            return "âœ… è¾¾æ ‡" if row['çœŸå®ROAS'] >= row['ç›®æ ‡æŒ‡æ ‡'] else "âŒ äºæŸ"
        keyword_summary['ç›ˆäºçŠ¶æ€'] = keyword_summary.apply(check_status, axis=1)

        # --- ç•Œé¢å±•ç¤º ---
        st.success("âœ… æ¯”ä¾‹åˆ†æå®Œæˆï¼æ‚¨å¯ä»¥æŸ¥çœ‹å„è¯åŠéæœç´¢åŒºåŸŸçš„é¢„ç®—åˆ†é…ã€‚")

        # æ•°æ®é¢„è§ˆä¸ç¾åŒ–
        st.dataframe(
            keyword_summary,
            column_config={
                "æ”¯å‡ºå æ¯”": st.column_config.NumberColumn("æ”¯å‡ºå æ¯”", format="%.2f%%"),
                "ç›®æ ‡æŒ‡æ ‡": st.column_config.NumberColumn("ç›®æ ‡æŒ‡æ ‡", format="%d%%"),
                "çœŸå®ROAS": st.column_config.NumberColumn("çœŸå®ROAS", format="%.2f%%"),
                "çœŸå®ç‚¹å‡»ç‡": st.column_config.NumberColumn("çœŸå®ç‚¹å‡»ç‡", format="%.2f%%"),
                "æ€»è½¬åŒ–é”€å”®é¢": st.column_config.NumberColumn("æ€»è½¬åŒ–é”€å”®é¢", format="â‚©%d"),
                "çœŸå®å¹¿å‘Šè´¹(å«ç¨)": st.column_config.NumberColumn("çœŸå®å¹¿å‘Šè´¹(å«ç¨)", format="â‚©%d"),
                "çœŸå®CPC": st.column_config.NumberColumn("çœŸå®CPC", format="â‚©%d")
            },
            hide_index=True,
            use_container_width=True
        )

        # æ–°å¢å¯è§†åŒ–ï¼šéæœç´¢åŒºåŸŸå æ¯”å›¾
        st.divider()
        st.subheader("ğŸ’¡ æŠ•æ”¾æ¯”ä¾‹å¯è§†åŒ–")
        
        # æå–éæœç´¢åŒºåŸŸå æ¯”
        non_search_data = keyword_summary[keyword_summary['å±•ç¤ºç‰ˆé¢'] == 'ë¹„ê²€ìƒ‰ ì˜ì—­'].copy() # æ³¨æ„éŸ©æ–‡æŠ¥è¡¨åŸè¯
        if non_search_data.empty:
            non_search_data = keyword_summary[keyword_summary['å…³é”®è¯'] == 'éæœç´¢åŒºåŸŸ'].copy()

        if not non_search_data.empty:
            st.bar_chart(non_search_data.set_index('äº§å“ç¼–å·')['æ”¯å‡ºå æ¯”'])
            st.info("ä¸Šæ–¹å›¾è¡¨æ˜¾ç¤ºäº†æ¯ä¸ªäº§å“ä¸­â€œéæœç´¢åŒºåŸŸâ€å ç”¨çš„é¢„ç®—ç™¾åˆ†æ¯”ã€‚")

        # ä¸‹è½½
        final_csv = keyword_summary.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è½½å®Œæ•´å æ¯”åˆ†ææŠ¥è¡¨", final_csv, "LxU_Spend_Share_Report.csv", "text/csv")

else:
    st.info("è¯·æ‰¹é‡ä¸Šä¼ å¹¿å‘ŠæŠ¥è¡¨ã€‚")
