import streamlit as st
import pandas as pd
import re

st.set_page_config(page_title="LxU å¹¿å‘Šæ™ºèƒ½å†³ç­–çœ‹æ¿", layout="wide")

st.title("ğŸš€ LxU å¹¿å‘Šå…¨ç»´åº¦æ˜ç»†çœ‹æ¿")
st.markdown("å·²è°ƒæ•´æ’åºï¼š**éæœç´¢åŒºåŸŸæ±‡æ€»**ç½®äºé¦–è¡Œï¼Œ**æ‰‹åŠ¨è¯**å±…ä¸­ï¼Œ**äº§å“æ€»è®¡**ç½®åº•ã€‚")

# 1. æ–‡ä»¶ä¸Šä¼ 
uploaded_files = st.file_uploader("æ‰¹é‡ä¸Šä¼ å¹¿å‘ŠæŠ¥è¡¨", type=['csv', 'xlsx'], accept_multiple_files=True)

if uploaded_files:
    all_data = []
    for file in uploaded_files:
        try:
            if file.name.endswith('.csv'):
                try:
                    df = pd.read_csv(file, encoding='cp949')
                except:
                    df = pd.read_csv(file, encoding='utf-8-sig')
            else:
                df = pd.read_excel(file)
            all_data.append(df)
        except Exception as e:
            st.error(f"è¯»å–æ–‡ä»¶ {file.name} å¤±è´¥: {e}")

    if all_data:
        raw_df = pd.concat(all_data, ignore_index=True)

        # 2. å±æ€§æå–å¼•æ“
        def extract_info(row):
            camp_name, grp_name = str(row.iloc[5]), str(row.iloc[6])
            full_text = f"{camp_name} {grp_name}"
            p_code = re.search(r'C\d{3,5}', full_text, re.IGNORECASE)
            p_code = p_code.group(0).upper() if p_code else "æœªè¯†åˆ«"
            target_match = re.search(r'ã€(\d+)ã€‘', full_text)
            target_val = int(target_match.group(1)) if target_match else 0
            date_match = re.search(r'ã€(\d{1,2}\.\d{1,2})ã€‘', full_text)
            mod_date = date_match.group(1) if date_match else "æ±‡æ€»"
            return pd.Series([p_code, target_val, mod_date])

        raw_df[['äº§å“ç¼–å·', 'ç›®æ ‡æŒ‡æ ‡', 'ç­–ç•¥æ—¥æœŸ']] = raw_df.apply(extract_info, axis=1)

        # 3. æ¸…æ´—ä¸å½’ä¸€åŒ–
        analysis_df = raw_df.copy()
        mask_ns = (analysis_df.iloc[:, 12].isna()) | \
                  (analysis_df.iloc[:, 11].str.contains('ë¹„ê²€ìƒ‰|éæœç´¢', na=False)) | \
                  (analysis_df.iloc[:, 12].astype(str) == 'nan')
        
        analysis_df.iloc[:, 12] = analysis_df.iloc[:, 12].astype(str).str.strip().replace({'nan': 'ğŸ¤– éæœç´¢åŒºåŸŸ', '': 'ğŸ¤– éæœç´¢åŒºåŸŸ'})
        analysis_df.iloc[:, 11] = analysis_df.iloc[:, 11].astype(str).str.strip()
        
        analysis_df.loc[mask_ns, analysis_df.columns[12]] = 'ğŸ¤– éæœç´¢åŒºåŸŸ'
        analysis_df.loc[mask_ns, analysis_df.columns[11]] = 'ğŸ¤– éæœç´¢åŒºåŸŸ'
        analysis_df.loc[mask_ns, 'ç­–ç•¥æ—¥æœŸ'] = 'æ±‡æ€»'

        analysis_df = analysis_df.rename(columns={
            analysis_df.columns[11]: 'å±•ç¤ºç‰ˆé¢', analysis_df.columns[12]: 'å…³é”®è¯',
            analysis_df.columns[13]: 'å±•ç¤º', analysis_df.columns[14]: 'ç‚¹å‡»',
            analysis_df.columns[15]: 'åŸæ”¯å‡º', analysis_df.columns[29]: 'é”€é‡', analysis_df.columns[32]: 'é”€å”®é¢'
        })

        # 4. èšåˆè®¡ç®—
        # a. å…³é”®è¯çº§æ˜ç»†
        kw_summary = analysis_df.groupby(['äº§å“ç¼–å·', 'å±•ç¤ºç‰ˆé¢', 'å…³é”®è¯', 'ç›®æ ‡æŒ‡æ ‡', 'ç­–ç•¥æ—¥æœŸ']).agg({
            'å±•ç¤º': 'sum', 'ç‚¹å‡»': 'sum', 'åŸæ”¯å‡º': 'sum', 'é”€é‡': 'sum', 'é”€å”®é¢': 'sum'
        }).reset_index()

        # b. äº§å“æ€»è®¡çº§
        product_sum = kw_summary.groupby('äº§å“ç¼–å·').agg({
            'å±•ç¤º': 'sum', 'ç‚¹å‡»': 'sum', 'åŸæ”¯å‡º': 'sum', 'é”€é‡': 'sum', 'é”€å”®é¢': 'sum', 'ç›®æ ‡æŒ‡æ ‡': 'max'
        }).reset_index()
        product_sum['å±•ç¤ºç‰ˆé¢'] = 'ğŸ“Œ æ€»è®¡'
        product_sum['å…³é”®è¯'] = 'ğŸ“Œ äº§å“æ€»è®¡'
        product_sum['ç­–ç•¥æ—¥æœŸ'] = 'TOTAL'

        # c. ã€æ ¸å¿ƒä¿®æ­£ã€‘è®¾ç½®æ’åºæƒé‡
        # æƒé‡ï¼šéæœç´¢=0, æ‰‹åŠ¨è¯=1, æ€»è®¡=2
        kw_summary['sort_weight'] = kw_summary['å…³é”®è¯'].apply(lambda x: 0 if 'éæœç´¢' in x else 1)
        product_sum['sort_weight'] = 2

        combined_df = pd.concat([kw_summary, product_sum], ignore_index=True)
        # æ’åºä¼˜å…ˆçº§ï¼šäº§å“ç¼–å· -> æƒé‡ -> æ”¯å‡º(é™åº)
        combined_df = combined_df.sort_values(['äº§å“ç¼–å·', 'sort_weight', 'åŸæ”¯å‡º'], ascending=[True, True, False])

        # 5. æŒ‡æ ‡è®¡ç®—
        combined_df['çœŸå®æ”¯å‡º'] = (combined_df['åŸæ”¯å‡º'] * 1.1).round(0)
        combined_df['çœŸå®ROAS'] = (combined_df['é”€å”®é¢'] / combined_df['çœŸå®æ”¯å‡º'] * 100).round(2)
        
        p_total_spend_map = product_sum.set_index('äº§å“ç¼–å·')['åŸæ”¯å‡º'] * 1.1
        combined_df['æ”¯å‡ºå æ¯”'] = combined_df.apply(
            lambda x: (x['çœŸå®æ”¯å‡º'] / p_total_spend_map[x['äº§å“ç¼–å·']] * 100) if x['sort_weight'] != 2 else 100.0, axis=1
        ).round(1)

        combined_df = combined_df.replace([float('inf'), -float('inf')], 0).fillna(0)

        # 6. ç•Œé¢æ¸²æŸ“
        unique_p = combined_df['äº§å“ç¼–å·'].unique()
        p_color_map = {p: '#f9f9f9' if i % 2 == 0 else '#ffffff' for i, p in enumerate(unique_p)}

        def apply_row_styles(row):
            base_color = p_color_map[row['äº§å“ç¼–å·']]
            # æ€»è®¡è¡Œæ ·å¼
            if row['sort_weight'] == 2:
                return ['background-color: #e8f4ea; font-weight: bold; border-top: 2px solid #ccc'] * len(row)
            # éæœç´¢è¡Œæ ·å¼ï¼ˆå¯é€‰ï¼šæµ…è“è‰²åŒºåˆ†ï¼‰
            if row['sort_weight'] == 0:
                return [f'background-color: {base_color}; color: #0056b3; font-weight: 500'] * len(row)
            return [f'background-color: {base_color}'] * len(row)

        st.dataframe(
            combined_df.style.apply(apply_row_styles, axis=1),
            column_config={
                "sort_weight": None, # éšè—æ’åºè¾…åŠ©åˆ—
                "æ”¯å‡ºå æ¯”": st.column_config.NumberColumn(format="%.1f%%"),
                "çœŸå®ROAS": st.column_config.NumberColumn(format="%.2f%%"),
                "ç›®æ ‡æŒ‡æ ‡": st.column_config.NumberColumn(format="%d%%"),
                "çœŸå®æ”¯å‡º": st.column_config.NumberColumn(format="â‚©%d"),
                "é”€å”®é¢": st.column_config.NumberColumn(format="â‚©%d")
            },
            hide_index=True,
            use_container_width=True,
            height=1000 # å†æ¬¡æ‹‰é•¿é¢„è§ˆçª—å£
        )

        # 7. ä¸‹è½½
        csv_data = combined_df.drop(columns=['sort_weight']).to_csv(index=False).encode('utf-8-sig')
        st.sidebar.download_button("ğŸ“¥ ä¸‹è½½å®Œæ•´æŠ¥å‘Š", csv_data, "LxU_Integrated_Report.csv", "text/csv")

else:
    st.info("ğŸ‘‹ è¯·æ‰¹é‡ä¸Šä¼ æŠ¥è¡¨ã€‚")
