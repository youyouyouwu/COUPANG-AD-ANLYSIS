import streamlit as st
import pandas as pd
import re

st.set_page_config(page_title="LxU å…³é”®è¯å…¨å‘¨æœŸåˆ†æ", layout="wide")

st.title("ğŸ“ˆ å…³é”®è¯å…¨å‘¨æœŸè¡¨ç°æ±‡æ€»")
st.markdown("è¯¥é¡µé¢å°†åˆå¹¶æ‰€æœ‰æ—¥æœŸæ•°æ®ï¼Œå±•ç¤ºæ¯ä¸ªäº§å“ä¸‹å„å…³é”®è¯çš„**æ•´ä½“äº§å‡ºæ¯”**ã€‚")

uploaded_files = st.file_uploader("æ‰¹é‡ä¸Šä¼ æŠ¥è¡¨", type=['csv', 'xlsx'], accept_multiple_files=True)

if uploaded_files:
    all_data = []
    for file in uploaded_files:
        try:
            # å…¼å®¹éŸ©æ–‡ç¼–ç 
            df = pd.read_csv(file, encoding='cp949') if file.name.endswith('.csv') else pd.read_excel(file)
            all_data.append(df)
        except:
            df = pd.read_csv(file, encoding='utf-8-sig')
            all_data.append(df)

    if all_data:
        raw_df = pd.concat(all_data, ignore_index=True)

        # 1. æå–å±æ€§ (äº§å“ç¼–å·, ç›®æ ‡æŒ‡æ ‡, ç­–ç•¥æ—¥æœŸ)
        def extract_info(row):
            camp_name = str(row.iloc[5]) if len(row) > 5 else ""
            grp_name = str(row.iloc[6]) if len(row) > 6 else ""
            full_text = f"{camp_name} {grp_name}"
            
            p_code = re.search(r'C\d{3,5}', full_text, re.IGNORECASE)
            p_code = p_code.group(0).upper() if p_code else "æœªè¯†åˆ«"
            
            target_match = re.search(r'ã€(\d+)ã€‘', full_text)
            target_val = int(target_match.group(1)) if target_match else 0
            
            date_match = re.search(r'ã€(\d{1,2}\.\d{1,2})ã€‘', full_text)
            mod_date = date_match.group(1) if date_match else "æœªçŸ¥"
            
            return pd.Series([p_code, target_val, mod_date])

        raw_df[['äº§å“ç¼–å·', 'ç›®æ ‡æŒ‡æ ‡', 'ç­–ç•¥æ—¥æœŸ']] = raw_df.apply(extract_info, axis=1)

        # 2. åˆ—åé‡å‘½å (æ ¹æ®ç´¢å¼• A, M, N, O, P, AD)
        analysis_df = raw_df.copy()
        analysis_df = analysis_df.rename(columns={
            analysis_df.columns[12]: 'å…³é”®è¯',
            analysis_df.columns[13]: 'æ€»å±•ç¤º',
            analysis_df.columns[14]: 'æ€»ç‚¹å‡»',
            analysis_df.columns[15]: 'åŸå§‹å¹¿å‘Šè´¹',
            analysis_df.columns[29]: 'æ€»é”€é‡'
        })

        # 3. æ‰§è¡Œå…¨å‘¨æœŸèšåˆ (å»æ‰äº†æ—¥æœŸç»´åº¦)
        # æŒ‰ äº§å“ç¼–å·ã€å…³é”®è¯ã€ç›®æ ‡æŒ‡æ ‡ è¿›è¡Œæ±‡æ€»
        keyword_summary = analysis_df.groupby(['äº§å“ç¼–å·', 'å…³é”®è¯', 'ç›®æ ‡æŒ‡æ ‡', 'ç­–ç•¥æ—¥æœŸ']).agg({
            'æ€»å±•ç¤º': 'sum',
            'æ€»ç‚¹å‡»': 'sum',
            'åŸå§‹å¹¿å‘Šè´¹': 'sum',
            'æ€»é”€é‡': 'sum'
        }).reset_index()

        # 4. æŒ‡æ ‡äºŒæ¬¡è®¡ç®—
        keyword_summary['çœŸå®å¹¿å‘Šè´¹(å«ç¨)'] = (keyword_summary['åŸå§‹å¹¿å‘Šè´¹'] * 1.1).round(0)
        keyword_summary['çœŸå®ROAS(%)'] = (keyword_summary['æ€»é”€é‡'] / keyword_summary['çœŸå®å¹¿å‘Šè´¹(å«ç¨)'] * 100).round(2)
        keyword_summary['çœŸå®ç‚¹å‡»ç‡(%)'] = (keyword_summary['æ€»ç‚¹å‡»'] / keyword_summary['æ€»å±•ç¤º'] * 100).round(2)
        keyword_summary['çœŸå®CPC'] = (keyword_summary['çœŸå®å¹¿å‘Šè´¹(å«ç¨)'] / keyword_summary['æ€»ç‚¹å‡»']).round(0)

        # æ¸…æ´—å¼‚å¸¸å€¼
        keyword_summary = keyword_summary.replace([float('inf'), -float('inf')], 0).fillna(0)

        # 5. ç›ˆäºçŠ¶æ€åˆ¤å®š
        def check_status(row):
            if row['ç›®æ ‡æŒ‡æ ‡'] == 0: return "æœªè®¾ç›®æ ‡"
            return "âœ… è¾¾æ ‡" if row['çœŸå®ROAS(%)'] >= row['ç›®æ ‡æŒ‡æ ‡'] else "âŒ äºæŸ"
        
        keyword_summary['ç›ˆäºçŠ¶æ€'] = keyword_summary.apply(check_status, axis=1)

        # --- ç•Œé¢å±•ç¤º ---
        st.success(f"âœ… æ±‡æ€»å®Œæˆï¼å·²åˆ†æ {len(keyword_summary)} ä¸ªç‹¬ç«‹å…³é”®è¯çš„é•¿æœŸè¡¨ç°ã€‚")

        # ä¾§è¾¹æ ï¼šå¿«é€Ÿç­›é€‰
        st.sidebar.header("æ•°æ®ç­›é€‰")
        selected_p = st.sidebar.multiselect("é€‰æ‹©äº§å“ç¼–å·", options=keyword_summary['äº§å“ç¼–å·'].unique())
        if selected_p:
            keyword_summary = keyword_summary[keyword_summary['äº§å“ç¼–å·'].isin(selected_p)]

        status_filter = st.sidebar.multiselect("ç›ˆäºçŠ¶æ€", options=["âœ… è¾¾æ ‡", "âŒ äºæŸ", "æœªè®¾ç›®æ ‡"])
        if status_filter:
            keyword_summary = keyword_summary[keyword_summary['ç›ˆäºçŠ¶æ€'].isin(status_filter)]

        # æ•°æ®è¡¨æ ¼ç¾åŒ–ï¼šä½¿ç”¨é¢œè‰²æ ‡è®°
        st.subheader("å…³é”®è¯å…¨å‘¨æœŸè¡¨ç°æ˜ç»†")
        
        # å®šä¹‰é«˜äº®å‡½æ•°
        def highlight_status(val):
            color = 'red' if val == "âŒ äºæŸ" else ('green' if val == "âœ… è¾¾æ ‡" else 'black')
            return f'color: {color}'

        st.dataframe(keyword_summary.style.applymap(highlight_status, subset=['ç›ˆäºçŠ¶æ€']))

        # ä¸‹è½½
        final_csv = keyword_summary.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è½½å…¨å‘¨æœŸæ±‡æ€»æŠ¥è¡¨", final_csv, "LxU_Keyword_Analysis.csv", "text/csv")

else:
    st.info("è¯·æ‰¹é‡ä¸Šä¼ ä¸€æ®µæ—¶é—´å†…çš„å¹¿å‘ŠæŠ¥è¡¨ï¼ˆå¦‚æœ€è¿‘7å¤©çš„å¤šä»½æŠ¥è¡¨ï¼‰ã€‚")
