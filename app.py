import streamlit as st
import pandas as pd
import re

st.set_page_config(page_title="LxU å¹¿å‘Šæ™ºèƒ½åˆ†æè¯Šæ–­", layout="wide")

st.title("ğŸ“Š LxU å¹¿å‘Šæ™ºèƒ½åˆ†æè¯Šæ–­çœ‹æ¿")
st.markdown("å·²è§£å†³ï¼š**éæœç´¢åŒºåŸŸå¤šæ—¥æœŸåˆå¹¶**é—®é¢˜ã€‚æ–°å¢ï¼š**è‡ªåŠ¨ä¼˜åŒ–å»ºè®®**æ¨¡å—ã€‚")

uploaded_files = st.file_uploader("æ‰¹é‡ä¸Šä¼ å¹¿å‘ŠæŠ¥è¡¨", type=['csv', 'xlsx'], accept_multiple_files=True)

if uploaded_files:
    all_data = []
    for file in uploaded_files:
        try:
            df = pd.read_csv(file, encoding='cp949') if file.name.endswith('.csv') else pd.read_excel(file)
            all_data.append(df)
        except:
            df = pd.read_csv(file, encoding='utf-8-sig')
            all_data.append(df)

    if all_data:
        raw_df = pd.concat(all_data, ignore_index=True)

        # 1. åŸºç¡€å±æ€§æå–
        def extract_info(row):
            camp_name, grp_name = str(row.iloc[5]), str(row.iloc[6])
            full_text = f"{camp_name} {grp_name}"
            p_code = re.search(r'C\d{3,5}', full_text, re.IGNORECASE)
            p_code = p_code.group(0).upper() if p_code else "æœªè¯†åˆ«"
            target_match = re.search(r'ã€(\d+)ã€‘', full_text)
            target_val = int(target_match.group(1)) if target_match else 0
            date_match = re.search(r'ã€(\d{1,2}\.\d{1,2})ã€‘', full_text)
            mod_date = date_match.group(1) if date_match else "æœªçŸ¥"
            return pd.Series([p_code, target_val, mod_date])

        raw_df[['äº§å“ç¼–å·', 'ç›®æ ‡æŒ‡æ ‡', 'ç­–ç•¥æ—¥æœŸ']] = raw_df.apply(extract_info, axis=1)

        # 2. æ ¸å¿ƒæ¸…æ´—ï¼šå¼ºåˆ¶åˆå¹¶éæœç´¢åŒºåŸŸ
        analysis_df = raw_df.copy()
        analysis_df.iloc[:, 12] = analysis_df.iloc[:, 12].astype(str).str.strip().replace({'nan': 'éæœç´¢åŒºåŸŸ', '': 'éæœç´¢åŒºåŸŸ'})
        analysis_df.iloc[:, 11] = analysis_df.iloc[:, 11].astype(str).str.strip()

        # è¯†åˆ«æ‰€æœ‰éæœç´¢è¡Œ
        mask_ns = (analysis_df.iloc[:, 12] == 'éæœç´¢åŒºåŸŸ') | (analysis_df.iloc[:, 11].str.contains('ë¹„ê²€ìƒ‰|éæœç´¢', na=False))
        
        # å¼ºåˆ¶æŠ¹å¹³å·®å¼‚åˆ—ï¼šå…³é”®è¯ã€ç‰ˆé¢ã€æ—¥æœŸå…¨éƒ¨å¯¹é½
        analysis_df.loc[mask_ns, analysis_df.columns[12]] = 'éæœç´¢åŒºåŸŸ'
        analysis_df.loc[mask_ns, analysis_df.columns[11]] = 'éæœç´¢åŒºåŸŸ'
        analysis_df.loc[mask_ns, 'ç­–ç•¥æ—¥æœŸ'] = 'æ±‡æ€»'
        # æŒ‡æ ‡å–è¯¥å“æœ€å¤§çš„ç›®æ ‡å€¼ï¼ˆé€šå¸¸ä¸€è‡´ï¼‰
        analysis_df.loc[mask_ns, 'ç›®æ ‡æŒ‡æ ‡'] = analysis_df.groupby('äº§å“ç¼–å·')['ç›®æ ‡æŒ‡æ ‡'].transform('max')

        analysis_df = analysis_df.rename(columns={
            analysis_df.columns[11]: 'å±•ç¤ºç‰ˆé¢', analysis_df.columns[12]: 'å…³é”®è¯',
            analysis_df.columns[13]: 'å±•ç¤º', analysis_df.columns[14]: 'ç‚¹å‡»',
            analysis_df.columns[15]: 'åŸæ”¯å‡º', analysis_df.columns[29]: 'é”€é‡', analysis_df.columns[32]: 'é”€å”®é¢'
        })

        # 3. èšåˆä¸å æ¯”è®¡ç®—
        summary = analysis_df.groupby(['äº§å“ç¼–å·', 'å±•ç¤ºç‰ˆé¢', 'å…³é”®è¯', 'ç›®æ ‡æŒ‡æ ‡', 'ç­–ç•¥æ—¥æœŸ']).agg({
            'å±•ç¤º': 'sum', 'ç‚¹å‡»': 'sum', 'åŸæ”¯å‡º': 'sum', 'é”€é‡': 'sum', 'é”€å”®é¢': 'sum'
        }).reset_index()

        summary['çœŸå®æ”¯å‡º'] = (summary['åŸæ”¯å‡º'] * 1.1).round(0)
        p_total_spend = summary.groupby('äº§å“ç¼–å·')['çœŸå®æ”¯å‡º'].transform('sum')
        summary['æ”¯å‡ºå æ¯”'] = (summary['çœŸå®æ”¯å‡º'] / p_total_spend * 100).round(2)
        summary['çœŸå®ROAS'] = (summary['é”€å”®é¢'] / summary['çœŸå®æ”¯å‡º'] * 100).round(2)
        summary['CPC'] = (summary['çœŸå®æ”¯å‡º'] / summary['ç‚¹å‡»']).round(0)
        summary = summary.replace([float('inf'), -float('inf')], 0).fillna(0)

        # 4. æ™ºèƒ½è¯Šæ–­é€»è¾‘ (Smart Insights)
        st.subheader("ğŸ’¡ æŠ•æ”¾ä¼˜åŒ–å»ºè®®")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # å¼‚å¸¸æ¶ˆè€—è¯ï¼šæ¶ˆè€—å äº§å“15%ä»¥ä¸Šä¸”é”€å”®é¢ä¸º0
            waste_words = summary[(summary['æ”¯å‡ºå æ¯”'] > 15) & (summary['é”€å”®é¢'] == 0) & (summary['å…³é”®è¯'] != 'éæœç´¢åŒºåŸŸ')]
            st.error(f"âš ï¸ æ— æ•ˆæ¶ˆè€—è¯: {len(waste_words)} ä¸ª")
            if not waste_words.empty: st.caption("å»ºè®®ï¼šé™ä½å‡ºä»·æˆ–å‰”é™¤ã€‚")
            
        with col2:
            # éæœç´¢è¿‡çƒ­ï¼šéæœç´¢å æ¯” > 50% ä¸” ROAS ä¸è¾¾æ ‡
            ns_overheat = summary[(summary['å…³é”®è¯'] == 'éæœç´¢åŒºåŸŸ') & (summary['æ”¯å‡ºå æ¯”'] > 50) & (summary['çœŸå®ROAS'] < summary['ç›®æ ‡æŒ‡æ ‡'])]
            st.warning(f"ğŸ“‰ éæœç´¢è¿‡çƒ­: {len(ns_overheat)} ä¸ªå“")
            if not ns_overheat.empty: st.caption("å»ºè®®ï¼šå…³é—­è¯¥å“éæœç´¢å¼€å…³ã€‚")

        with col3:
            # é«˜æ½œçˆ†æ¬¾ï¼šROAS > ç›®æ ‡2å€ ä¸” æ¶ˆè€—å æ¯” < 20%
            potential_stars = summary[(summary['çœŸå®ROAS'] > summary['ç›®æ ‡æŒ‡æ ‡']*2) & (summary['æ”¯å‡ºå æ¯”'] < 20) & (summary['ç›®æ ‡æŒ‡æ ‡'] > 0)]
            st.success(f"ğŸš€ é«˜æ½œå…³é”®è¯: {len(potential_stars)} ä¸ª")
            if not potential_stars.empty: st.caption("å»ºè®®ï¼šå¢åŠ å‡ºä»·è·å–æµé‡ã€‚")

        # 5. æ•°æ®æ˜ç»†å±•ç¤º
        st.divider()
        st.dataframe(
            summary,
            column_config={
                "æ”¯å‡ºå æ¯”": st.column_config.NumberColumn(format="%.2f%%"),
                "ç›®æ ‡æŒ‡æ ‡": st.column_config.NumberColumn(format="%d%%"),
                "çœŸå®ROAS": st.column_config.NumberColumn(format="%.2f%%"),
                "é”€å”®é¢": st.column_config.NumberColumn(format="â‚©%d"),
                "çœŸå®æ”¯å‡º": st.column_config.NumberColumn(format="â‚©%d")
            },
            hide_index=True, use_container_width=True
        )

        csv = summary.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è½½å®Œæ•´è¯Šæ–­æŠ¥å‘Š", csv, "LxU_Smart_Analysis.csv", "text/csv")
else:
    st.info("è¯·æ‰¹é‡ä¸Šä¼ å¹¿å‘ŠæŠ¥è¡¨ã€‚")
