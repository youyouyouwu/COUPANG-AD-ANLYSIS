import streamlit as st
import pandas as pd
import re

st.set_page_config(page_title="LxU å¹¿å‘Šå…¨ç»´åº¦æ±‡æ€»", layout="wide")

st.title("ğŸ“ˆ å…³é”®è¯ä¸ç‰ˆé¢å…¨å‘¨æœŸæ±‡æ€»")
st.markdown("å·²åŠ å…¥ï¼š**éæœç´¢åŒºåŸŸ**æ±‡æ€»é€»è¾‘ã€‚Måˆ—ä¸ºç©ºçš„æ•°æ®å°†è‡ªåŠ¨æ ‡è®°å¹¶è®¡ç®—ã€‚")

uploaded_files = st.file_uploader("æ‰¹é‡ä¸Šä¼ æŠ¥è¡¨", type=['csv', 'xlsx'], accept_multiple_files=True)

if uploaded_files:
    all_data = []
    for file in uploaded_files:
        try:
            df = pd.read_csv(file, encoding='cp949') if file.name.endswith('.csv') else pd.read_excel(file)
            all_data.append(df)
        except:
            df = pd.read_csv(file, encoding='utf-8-sig')
            all_data.append(df)

    if all_data:
        raw_df = pd.concat(all_data, ignore_index=True)

        # 1. å±æ€§æå–å‡½æ•°
        def extract_info(row):
            camp_name = str(row.iloc[5]) if len(row) > 5 else ""
            grp_name = str(row.iloc[6]) if len(row) > 6 else ""
            full_text = f"{camp_name} {grp_name}"
            
            p_code = re.search(r'C\d{3,5}', full_text, re.IGNORECASE)
            p_code = p_code.group(0).upper() if p_code else "æœªè¯†åˆ«"
            
            target_match = re.search(r'ã€(\d+)ã€‘', full_text)
            target_val = int(target_match.group(1)) if target_match else 0
            
            date_match = re.search(r'ã€(\d{1,2}\.\d{1,2})ã€‘', full_text)
            mod_date = date_match.group(1) if date_match else "æœªçŸ¥"
            
            return pd.Series([p_code, target_val, mod_date])

        raw_df[['äº§å“ç¼–å·', 'ç›®æ ‡æŒ‡æ ‡', 'ç­–ç•¥æ—¥æœŸ']] = raw_df.apply(extract_info, axis=1)

        # 2. åˆ—åæ˜ å°„ä¸é¢„å¤„ç†
        analysis_df = raw_df.copy()
        
        # ç‰¹æ®Šå¤„ç† M åˆ—ï¼ˆå…³é”®è¯ï¼‰ï¼šå¦‚æœä¸ºç©ºï¼Œåˆ™æ ¹æ® L åˆ—æˆ–ç›´æ¥æ ‡è®°ä¸ºéæœç´¢åŒºåŸŸ
        # Måˆ—ç´¢å¼•ä¸º 12ï¼ŒLåˆ—ç´¢å¼•ä¸º 11
        analysis_df.iloc[:, 12] = analysis_df.iloc[:, 12].fillna("éæœç´¢åŒºåŸŸ")

        analysis_df = analysis_df.rename(columns={
            analysis_df.columns[11]: 'å±•ç¤ºç‰ˆé¢', # Låˆ—
            analysis_df.columns[12]: 'å…³é”®è¯',   # Måˆ—
            analysis_df.columns[13]: 'æ€»å±•ç¤º',   # Nåˆ—
            analysis_df.columns[14]: 'æ€»ç‚¹å‡»',   # Oåˆ—
            analysis_df.columns[15]: 'åŸå§‹å¹¿å‘Šè´¹', # Påˆ—
            analysis_df.columns[29]: 'æ€»é”€é‡(å•æ•°)', # ADåˆ—
            analysis_df.columns[32]: 'æ€»è½¬åŒ–é”€å”®é¢'  # AGåˆ—
        })

        # 3. æ‰§è¡Œå…¨å‘¨æœŸèšåˆ
        # å¢åŠ â€œå±•ç¤ºç‰ˆé¢â€ä½œä¸ºèšåˆç»´åº¦ï¼Œè¿™æ ·å¯ä»¥åŒºåˆ† å…³é”®è¯ å’Œ éæœç´¢åŒºåŸŸ
        keyword_summary = analysis_df.groupby(['äº§å“ç¼–å·', 'å±•ç¤ºç‰ˆé¢', 'å…³é”®è¯', 'ç›®æ ‡æŒ‡æ ‡', 'ç­–ç•¥æ—¥æœŸ']).agg({
            'æ€»å±•ç¤º': 'sum',
            'æ€»ç‚¹å‡»': 'sum',
            'åŸå§‹å¹¿å‘Šè´¹': 'sum',
            'æ€»é”€é‡(å•æ•°)': 'sum',
            'æ€»è½¬åŒ–é”€å”®é¢': 'sum'
        }).reset_index()

        # 4. æŒ‡æ ‡è®¡ç®—
        keyword_summary['çœŸå®å¹¿å‘Šè´¹(å«ç¨)'] = (keyword_summary['åŸå§‹å¹¿å‘Šè´¹'] * 1.1).round(0)
        keyword_summary['çœŸå®ROAS'] = (keyword_summary['æ€»è½¬åŒ–é”€å”®é¢'] / keyword_summary['çœŸå®å¹¿å‘Šè´¹(å«ç¨)'] * 100).round(2)
        keyword_summary['çœŸå®ç‚¹å‡»ç‡'] = (keyword_summary['æ€»ç‚¹å‡»'] / keyword_summary['æ€»å±•ç¤º'] * 100).round(2)
        keyword_summary['çœŸå®CPC'] = (keyword_summary['çœŸå®å¹¿å‘Šè´¹(å«ç¨)'] / keyword_summary['æ€»ç‚¹å‡»']).round(0)

        keyword_summary = keyword_summary.replace([float('inf'), -float('inf')], 0).fillna(0)

        # 5. ç›ˆäºçŠ¶æ€åˆ¤å®š
        def check_status(row):
            if row['ç›®æ ‡æŒ‡æ ‡'] == 0: return "æœªè®¾ç›®æ ‡"
            return "âœ… è¾¾æ ‡" if row['çœŸå®ROAS'] >= row['ç›®æ ‡æŒ‡æ ‡'] else "âŒ äºæŸ"
        
        keyword_summary['ç›ˆäºçŠ¶æ€'] = keyword_summary.apply(check_status, axis=1)

        # --- ç•Œé¢å±•ç¤º ---
        st.success(f"âœ… æ±‡æ€»å®Œæˆï¼å·²åŒ…å«â€œéæœç´¢åŒºåŸŸâ€æ•°æ®çš„ç»Ÿè®¡ã€‚")

        # ç­›é€‰å™¨
        st.sidebar.header("æ•°æ®ç­›é€‰")
        area_filter = st.sidebar.multiselect("ç‰ˆé¢ç­›é€‰", options=keyword_summary['å±•ç¤ºç‰ˆé¢'].unique(), default=keyword_summary['å±•ç¤ºç‰ˆé¢'].unique())
        if area_filter:
            keyword_summary = keyword_summary[keyword_summary['å±•ç¤ºç‰ˆé¢'].isin(area_filter)]

        # æ ¼å¼åŒ–æ˜¾ç¤º
        st.dataframe(
            keyword_summary,
            column_config={
                "ç›®æ ‡æŒ‡æ ‡": st.column_config.NumberColumn("ç›®æ ‡æŒ‡æ ‡", format="%d%%"),
                "çœŸå®ROAS": st.column_config.NumberColumn("çœŸå®ROAS", format="%.2f%%"),
                "çœŸå®ç‚¹å‡»ç‡": st.column_config.NumberColumn("çœŸå®ç‚¹å‡»ç‡", format="%.2f%%"),
                "æ€»è½¬åŒ–é”€å”®é¢": st.column_config.NumberColumn("æ€»è½¬åŒ–é”€å”®é¢", format="â‚©%d"),
                "çœŸå®å¹¿å‘Šè´¹(å«ç¨)": st.column_config.NumberColumn("çœŸå®å¹¿å‘Šè´¹(å«ç¨)", format="â‚©%d"),
                "çœŸå®CPC": st.column_config.NumberColumn("çœŸå®CPC", format="â‚©%d")
            },
            hide_index=True,
            use_container_width=True
        )

        # ä¸‹è½½
        final_csv = keyword_summary.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è½½å«éæœç´¢åŒºåŸŸæŠ¥è¡¨", final_csv, "LxU_Full_Area_Report.csv", "text/csv")

else:
    st.info("è¯·æ‰¹é‡ä¸Šä¼ å¹¿å‘ŠæŠ¥è¡¨ã€‚")
