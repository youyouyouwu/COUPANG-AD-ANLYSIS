import streamlit as st
import pandas as pd
import re

st.set_page_config(page_title="LxU å¹¿å‘Šæ¸…æ´—åˆ†æ - è¿›é˜¶ç‰ˆ", layout="wide")

st.title("ğŸ“Š å¹¿å‘ŠæŠ¥è¡¨å¤šç»´åº¦æ¸…æ´—")
st.markdown("å·²åŠ å…¥ï¼š**äº§å“ç¼–å·**ã€**ç›®æ ‡æŒ‡æ ‡**ã€**ç­–ç•¥æ—¥æœŸ** çš„è‡ªåŠ¨æå–åŠŸèƒ½ã€‚")

uploaded_files = st.file_uploader("æ‰¹é‡ä¸Šä¼ æŠ¥è¡¨", type=['csv', 'xlsx'], accept_multiple_files=True)

if uploaded_files:
    all_data = []
    for file in uploaded_files:
        try:
            df = pd.read_csv(file, encoding='cp949') if file.name.endswith('.csv') else pd.read_excel(file)
            all_data.append(df)
        except:
            # å¤‡é€‰ç¼–ç å¤„ç†
            df = pd.read_csv(file, encoding='utf-8-sig')
            all_data.append(df)

    if all_data:
        raw_df = pd.concat(all_data, ignore_index=True)

        def extract_info(row):
            # è·å– Fåˆ—(ç´¢å¼•5) å’Œ Gåˆ—(ç´¢å¼•6)
            camp_name = str(row.iloc[5]) if len(row) > 5 else ""
            grp_name = str(row.iloc[6]) if len(row) > 6 else ""
            full_text = f"{camp_name} {grp_name}"

            # 1. æå–äº§å“ç¼–å· (C001, C0001)
            code_match = re.search(r'C\d{3,5}', full_text, re.IGNORECASE)
            p_code = code_match.group(0).upper() if code_match else "æœªè¯†åˆ«"

            # 2. æå–ç›®æ ‡æŒ‡æ ‡ (åŒ¹é… ã€409ã€‘ è¿™ç§çº¯æ•°å­—)
            target_match = re.search(r'ã€(\d+)ã€‘', full_text)
            target_val = target_match.group(1) if target_match else "æœªè®¾ç½®"

            # 3. æå–æ”¹åŠ¨æ—¥æœŸ (åŒ¹é… ã€5.22ã€‘ è¿™ç§å¸¦ç‚¹çš„æ—¥æœŸ)
            date_match = re.search(r'ã€(\d{1,2}\.\d{1,2})ã€‘', full_text)
            mod_date = date_match.group(1) if date_match else "æœªçŸ¥æ—¥æœŸ"

            return pd.Series([p_code, target_val, mod_date])

        # åº”ç”¨æå–
        st.info("ğŸ” æ­£åœ¨æ·±åº¦è§£æå¹¿å‘Šåç§°ä¸­çš„åµŒå…¥å±æ€§...")
        raw_df[['äº§å“ç¼–å·', 'ç›®æ ‡æŒ‡æ ‡', 'ç­–ç•¥æ—¥æœŸ']] = raw_df.apply(extract_info, axis=1)

        # æ•´ç†åˆ—é¡ºåºï¼šå°†æ–°æå–çš„å±æ€§æ”¾åœ¨æœ€å‰é¢
        new_cols = ['äº§å“ç¼–å·', 'ç›®æ ‡æŒ‡æ ‡', 'ç­–ç•¥æ—¥æœŸ']
        other_cols = [c for c in raw_df.columns if c not in new_cols]
        cleaned_df = raw_df[new_cols + other_cols]

        # --- ç•Œé¢å±•ç¤º ---
        st.success("âœ… å¤šç»´åº¦ç‰¹å¾æå–å®Œæˆï¼")
        
        # æ•°æ®ç»Ÿè®¡ä»ªè¡¨ç›˜
        c1, c2, c3 = st.columns(3)
        c1.metric("è¯†åˆ«äº§å“æ•°", len(cleaned_df['äº§å“ç¼–å·'].unique()))
        c2.metric("å·²è®¾ç›®æ ‡å¹¿å‘Šæ•°", len(cleaned_df[cleaned_df['ç›®æ ‡æŒ‡æ ‡'] != "æœªè®¾ç½®"]))
        c3.metric("æœ€è¿‘ç­–ç•¥æ—¥æœŸ", cleaned_df['ç­–ç•¥æ—¥æœŸ'].max() if not cleaned_df.empty else "-")

        st.subheader("æ¸…æ´—åç»“æœï¼ˆå‰50è¡Œï¼‰")
        st.dataframe(cleaned_df.head(50))

        # ä¸‹è½½åŒºåŸŸ
        csv_data = cleaned_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è½½å®Œæ•´æ¸…æ´—æŠ¥è¡¨", csv_data, "LxU_Cleaned_Report.csv", "text/csv")
        
        st.session_state['cleaned_df'] = cleaned_df

else:
    st.info("è¯·ä¸Šä¼ æ–‡ä»¶å¼€å§‹æ·±åº¦æ¸…æ´—ã€‚")
